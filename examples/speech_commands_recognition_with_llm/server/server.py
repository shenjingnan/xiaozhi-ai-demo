#!/usr/bin/env python3
"""
ESP32éŸ³é¢‘WebSocketæœåŠ¡å™¨
é€šè¿‡WebSocketä¸ESP32åŒå‘é€šä¿¡
"""

import os
import sys
import json
import base64
import wave
import asyncio
import websockets
from datetime import datetime
from pydub import AudioSegment
import time
from send_custom_audio import get_custom_audio

# å°è¯•å¯¼å…¥æœåŠ¡å™¨ç‰ˆæœ¬çš„å®¢æˆ·ç«¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸç‰ˆ
try:
    from examples.speech_commands_recognition_with_llm.server.omni_realtime_client import (
        OmniRealtimeClient,
        TurnDetectionMode,
    )

    OMNI_CLIENT_AVAILABLE = True
    print("âœ… ä½¿ç”¨æœåŠ¡å™¨ç‰ˆæœ¬çš„å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆä¼˜åŒ–æ—¥å¿—è¾“å‡ºï¼‰")
except ImportError:
    # æ·»åŠ model_demoç›®å½•åˆ°sys.path
    sys.path.append(os.path.join(os.path.dirname(__file__), "../model_demo"))
    try:
        from omni_realtime_client import OmniRealtimeClient, TurnDetectionMode

        OMNI_CLIENT_AVAILABLE = True
        print("âš ï¸  ä½¿ç”¨åŸç‰ˆå¤§æ¨¡å‹å®¢æˆ·ç«¯")
    except ImportError:
        print("âš ï¸  è­¦å‘Š: æ— æ³•å¯¼å…¥omni_realtime_clientï¼Œå°†ä½¿ç”¨é»˜è®¤éŸ³é¢‘å“åº”")
        OMNI_CLIENT_AVAILABLE = False

# éŸ³é¢‘å‚æ•°é…ç½®
SAMPLE_RATE = 16000  # ESP32ä½¿ç”¨çš„é‡‡æ ·ç‡ 16kHz
MODEL_SAMPLE_RATE = 24000  # å¤§æ¨¡å‹è¾“å‡ºçš„é‡‡æ ·ç‡ 24kHz
CHANNELS = 1  # å•å£°é“
BIT_DEPTH = 16  # 16ä½
BYTES_PER_SAMPLE = 2  # 16ä½ = 2å­—èŠ‚

# WebSocketæœåŠ¡å™¨é…ç½®
WS_HOST = "0.0.0.0"  # ç›‘å¬æ‰€æœ‰æ¥å£
WS_PORT = 8888  # WebSocketç«¯å£


class WebSocketAudioServer:
    """WebSocketéŸ³é¢‘æœåŠ¡å™¨"""

    def __init__(self):
        self.output_dir = os.path.join(os.path.dirname(__file__), "user_records")
        self.response_dir = os.path.join(os.path.dirname(__file__), "response_records")
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.response_dir, exist_ok=True)

        # åˆå§‹åŒ–Omni Realtimeå®¢æˆ·ç«¯
        self.api_key = os.environ.get("DASHSCOPE_API_KEY")
        if not self.api_key or not OMNI_CLIENT_AVAILABLE:
            if not self.api_key:
                print(
                    "âš ï¸  è­¦å‘Š: æœªè®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡ï¼Œå°†ä½¿ç”¨é»˜è®¤light_onéŸ³é¢‘"
                )
            self.use_model = False
        else:
            self.use_model = True
            print("âœ… å·²é…ç½®å¤§æ¨¡å‹APIï¼Œå°†ä½¿ç”¨AIç”Ÿæˆå“åº”éŸ³é¢‘")

        # æ— è®ºæ˜¯å¦ä½¿ç”¨æ¨¡å‹ï¼Œéƒ½åŠ è½½é»˜è®¤éŸ³é¢‘ä½œä¸ºå¤‡ç”¨
        self.response_audio = get_custom_audio("light_on")
        print(
            f"âœ… å·²åŠ è½½å¤‡ç”¨å“åº”éŸ³é¢‘: {len(self.response_audio)} å­—èŠ‚ (çº¦{len(self.response_audio)/2/SAMPLE_RATE:.1f}ç§’)"
        )

    async def handle_client(self, websocket, path):
        """å¤„ç†å®¢æˆ·ç«¯è¿æ¥"""
        client_ip = websocket.remote_address[0]
        print(f"\nğŸ”— æ–°çš„å®¢æˆ·ç«¯è¿æ¥: {client_ip}")

        try:
            async for message in websocket:
                try:
                    # æ£€æŸ¥æ¶ˆæ¯ç±»å‹
                    if isinstance(message, bytes):
                        # äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
                        print(
                            f"ğŸ¤ [{client_ip}] æ¥æ”¶åˆ°äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®: {len(message)} å­—èŠ‚"
                        )

                        # ä¿å­˜éŸ³é¢‘
                        current_timestamp = datetime.now()
                        saved_file = await self.save_audio([message], current_timestamp)
                        if saved_file:
                            print(f"âœ… [{client_ip}] éŸ³é¢‘å·²ä¿å­˜: {saved_file}")

                        # ç­‰å¾…ä¸€ä¸‹å†å‘é€å“åº”
                        print(f"â³ [{client_ip}] ç­‰å¾…0.5ç§’åå‘é€å“åº”éŸ³é¢‘...")
                        await asyncio.sleep(0.5)

                        # å‘é€å“åº”éŸ³é¢‘
                        if self.use_model:
                            await self.send_model_response_audio(
                                websocket, client_ip, message
                            )
                        else:
                            await self.send_response_audio(websocket, client_ip)
                        continue

                    # è§£æJSONæ¶ˆæ¯
                    data = json.loads(message)
                    event = data.get("event")

                    if event == "wake_word_detected":
                        print(f"ğŸ‰ [{client_ip}] æ£€æµ‹åˆ°å”¤é†’è¯ï¼")

                    elif event == "audio_data":
                        # JSONæ ¼å¼çš„éŸ³é¢‘æ•°æ®ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰
                        audio_base64 = data.get("data", "")
                        audio_size = data.get("size", 0)

                        print(
                            f"ğŸ¤ [{client_ip}] æ¥æ”¶åˆ°JSONæ ¼å¼éŸ³é¢‘æ•°æ®: {audio_size} å­—èŠ‚"
                        )

                        try:
                            # Base64è§£ç 
                            audio_bytes = base64.b64decode(audio_base64)

                            # ä¿å­˜éŸ³é¢‘
                            current_timestamp = datetime.now()
                            saved_file = await self.save_audio(
                                [audio_bytes], current_timestamp
                            )
                            if saved_file:
                                print(f"âœ… [{client_ip}] éŸ³é¢‘å·²ä¿å­˜: {saved_file}")

                            # ç­‰å¾…ä¸€ä¸‹å†å‘é€å“åº”
                            print(f"â³ [{client_ip}] ç­‰å¾…0.5ç§’åå‘é€å“åº”éŸ³é¢‘...")
                            await asyncio.sleep(0.5)

                            # å‘é€å“åº”éŸ³é¢‘
                            if self.use_model:
                                await self.send_model_response_audio(
                                    websocket, client_ip, audio_bytes
                                )
                            else:
                                await self.send_response_audio(websocket, client_ip)

                        except Exception as e:
                            print(f"âŒ [{client_ip}] éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")

                except json.JSONDecodeError as e:
                    print(f"âŒ [{client_ip}] JSONè§£æé”™è¯¯: {e}")
                except Exception as e:
                    print(f"âŒ [{client_ip}] å¤„ç†æ¶ˆæ¯é”™è¯¯: {e}")

        except websockets.exceptions.ConnectionClosed:
            print(f"ğŸ”Œ [{client_ip}] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
        except Exception as e:
            print(f"âŒ [{client_ip}] è¿æ¥é”™è¯¯: {e}")

    async def send_model_response_audio(self, websocket, client_ip, user_audio_data):
        """ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆå¹¶å‘é€å“åº”éŸ³é¢‘ï¼ˆæµå¼ï¼‰"""
        print(f"ğŸ¤– [{client_ip}] ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆå“åº”éŸ³é¢‘ï¼ˆæµå¼ï¼‰...")

        try:
            total_audio_sent = 0
            stream_complete = False
            last_sent_time = time.time()
            
            # å®šä¹‰æµå¼éŸ³é¢‘å¤„ç†å‡½æ•°
            async def on_audio_delta(audio_data):
                """ç›´æ¥å¤„ç†å¹¶å‘é€éŸ³é¢‘ç‰‡æ®µåˆ°ESP32"""
                nonlocal total_audio_sent, last_sent_time
                try:
                    # ç›´æ¥é‡é‡‡æ ·å¹¶å‘é€éŸ³é¢‘æ•°æ®
                    # audio_data æ˜¯ 24kHz çš„éŸ³é¢‘æ•°æ®ï¼Œéœ€è¦è½¬æ¢ä¸º 16kHz
                    resampled = self.resample_audio(
                        audio_data, MODEL_SAMPLE_RATE, SAMPLE_RATE
                    )
                    
                    # ç«‹å³å‘é€åˆ°ESP32
                    await websocket.send(resampled)
                    total_audio_sent += len(resampled)
                    last_sent_time = time.time()  # æ›´æ–°æœ€åå‘é€æ—¶é—´
                    print(f"   â†’ æµå¼å‘é€éŸ³é¢‘å—: {len(resampled)} å­—èŠ‚")
                    
                except Exception as e:
                    print(f"âŒ [{client_ip}] å‘é€éŸ³é¢‘å—å¤±è´¥: {e}")

            # åˆ›å»ºå¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆå‚è€ƒqwen_demo.pyçš„å®ç°ï¼‰
            realtime_client = OmniRealtimeClient(
                base_url="wss://dashscope.aliyuncs.com/api-ws/v1/realtime",
                api_key=self.api_key,
                model="qwen-omni-turbo-realtime-2025-05-08",
                voice="Chelsie",
                on_audio_delta=lambda audio: asyncio.create_task(on_audio_delta(audio)),
                turn_detection_mode=TurnDetectionMode.MANUAL,  # ä½¿ç”¨æ‰‹åŠ¨æ¨¡å¼ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦æ§åˆ¶ä½•æ—¶ç”Ÿæˆå“åº”
            )

            # è¿æ¥åˆ°å¤§æ¨¡å‹
            await realtime_client.connect()

            # å¯åŠ¨æ¶ˆæ¯å¤„ç†
            message_task = asyncio.create_task(realtime_client.handle_messages())

            # å‘é€ç”¨æˆ·éŸ³é¢‘æ•°æ®
            print(f"   å‘é€ç”¨æˆ·éŸ³é¢‘åˆ°å¤§æ¨¡å‹: {len(user_audio_data)} å­—èŠ‚")

            # å°†éŸ³é¢‘æ•°æ®åˆ†å—å‘é€ï¼ˆå‚è€ƒmain.pyçš„å®ç°ï¼‰
            chunk_size = 3200  # æ¯ä¸ªå—200msçš„éŸ³é¢‘æ•°æ®ï¼ˆ16kHz * 2å­—èŠ‚ * 0.2ç§’ï¼‰
            for i in range(0, len(user_audio_data), chunk_size):
                chunk = user_audio_data[i : i + chunk_size]
                # Base64ç¼–ç éŸ³é¢‘æ•°æ®
                encoded_data = base64.b64encode(chunk).decode("utf-8")

                # æ„å»ºäº‹ä»¶ï¼ˆå‚è€ƒmain.pyçš„æ ¼å¼ï¼‰
                event = {
                    "event_id": "event_" + str(int(time.time() * 1000)),
                    "type": "input_audio_buffer.append",
                    "audio": encoded_data,
                }
                await realtime_client.send_event(event)

                # å°å»¶è¿Ÿé¿å…è¿‡å¿«å‘é€
                await asyncio.sleep(0.01)

            # æ‰‹åŠ¨è§¦å‘å“åº”ç”Ÿæˆ
            await realtime_client.create_response()

            # ç­‰å¾…å“åº”ç”Ÿæˆå’Œå‘é€å®Œæˆ
            max_wait_time = 30  # æœ€å¤šç­‰å¾…30ç§’
            start_time = time.time()
            
            while time.time() - start_time < max_wait_time:
                await asyncio.sleep(0.1)
                
                # å¦‚æœè¶…è¿‡1ç§’æ²¡æœ‰æ–°çš„éŸ³é¢‘æ•°æ®å‘é€ï¼Œè®¤ä¸ºæµç»“æŸ
                if total_audio_sent > 0 and time.time() - last_sent_time > 1.0:
                    stream_complete = True
                    break
            
            # å‘é€pingä½œä¸ºéŸ³é¢‘ç»“æŸæ ‡å¿—
            await websocket.ping()
            
            # å–æ¶ˆæ¶ˆæ¯ä»»åŠ¡å¹¶å…³é—­è¿æ¥
            try:
                message_task.cancel()
                await message_task
            except asyncio.CancelledError:
                pass
            await realtime_client.close()
            
            if total_audio_sent > 0:
                print(f"âœ… [{client_ip}] æµå¼éŸ³é¢‘å‘é€å®Œæˆï¼Œæ€»è®¡: {total_audio_sent} å­—èŠ‚ ({total_audio_sent/2/SAMPLE_RATE:.2f}ç§’)")
            else:
                print(f"âš ï¸  [{client_ip}] æœªæ”¶åˆ°å¤§æ¨¡å‹å“åº”ï¼Œä½¿ç”¨é»˜è®¤éŸ³é¢‘")
                await self.send_response_audio_stream(websocket, client_ip)

        except Exception as e:
            print(f"âŒ [{client_ip}] å¤§æ¨¡å‹å¤„ç†å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            # å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤éŸ³é¢‘
            await self.send_response_audio(websocket, client_ip)

    async def send_response_audio(self, websocket, client_ip):
        """å‘é€é»˜è®¤å“åº”éŸ³é¢‘åˆ°ESP32ï¼ˆä¿æŒåŸæœ‰çš„ä¸€æ¬¡æ€§å‘é€æ–¹å¼ï¼‰"""
        print(f"ğŸ“¤ [{client_ip}] å‘é€é»˜è®¤å“åº”éŸ³é¢‘...")

        try:
            # ç›´æ¥å‘é€äºŒè¿›åˆ¶PCMæ•°æ®
            print(f"   éŸ³é¢‘æ•°æ®é•¿åº¦: {len(self.response_audio)} å­—èŠ‚")
            print(f"   éŸ³é¢‘æ—¶é•¿: {len(self.response_audio) / 2 / SAMPLE_RATE:.2f} ç§’")

            # ä¸€æ¬¡æ€§å‘é€æ‰€æœ‰äºŒè¿›åˆ¶æ•°æ®
            await websocket.send(self.response_audio)

            # å‘é€ä¸€ä¸ªpingåŒ…ä½œä¸ºéŸ³é¢‘ç»“æŸæ ‡å¿—
            await websocket.ping()

            print(f"âœ… [{client_ip}] å“åº”éŸ³é¢‘å‘é€å®Œæˆ")

        except Exception as e:
            print(f"âŒ [{client_ip}] å‘é€éŸ³é¢‘å¤±è´¥: {e}")
    
    async def send_response_audio_stream(self, websocket, client_ip):
        """æµå¼å‘é€é»˜è®¤å“åº”éŸ³é¢‘åˆ°ESP32"""
        print(f"ğŸ“¤ [{client_ip}] æµå¼å‘é€é»˜è®¤å“åº”éŸ³é¢‘...")

        try:
            # åˆ†å—å‘é€éŸ³é¢‘æ•°æ®
            CHUNK_SIZE = 3200  # æ¯200msçš„éŸ³é¢‘æ•°æ®ï¼ˆ16kHz * 2å­—èŠ‚ * 0.2ç§’ï¼‰
            total_sent = 0
            
            for i in range(0, len(self.response_audio), CHUNK_SIZE):
                chunk = self.response_audio[i:i + CHUNK_SIZE]
                await websocket.send(chunk)
                total_sent += len(chunk)
                print(f"   â†’ å‘é€éŸ³é¢‘å—: {len(chunk)} å­—èŠ‚")
                # å°å»¶è¿Ÿæ¨¡æ‹Ÿæµå¼æ•ˆæœ
                await asyncio.sleep(0.05)

            # å‘é€ä¸€ä¸ªpingåŒ…ä½œä¸ºéŸ³é¢‘ç»“æŸæ ‡å¿—
            await websocket.ping()

            print(f"âœ… [{client_ip}] æµå¼éŸ³é¢‘å‘é€å®Œæˆï¼Œæ€»è®¡: {total_sent} å­—èŠ‚")

        except Exception as e:
            print(f"âŒ [{client_ip}] æµå¼å‘é€å¤±è´¥: {e}")

    async def save_audio(self, audio_buffer, timestamp):
        """ä¿å­˜éŸ³é¢‘æ•°æ®ä¸ºMP3æ–‡ä»¶"""
        if not audio_buffer:
            print("âš ï¸  æ²¡æœ‰éŸ³é¢‘æ•°æ®å¯ä¿å­˜")
            return None

        try:
            # åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ•°æ®
            audio_data = b"".join(audio_buffer)

            # ç”Ÿæˆæ–‡ä»¶å
            timestamp_str = (
                timestamp.strftime("%Y%m%d_%H%M%S")
                if timestamp
                else datetime.now().strftime("%Y%m%d_%H%M%S")
            )
            wav_filename = os.path.join(
                self.output_dir, f"recording_{timestamp_str}.wav"
            )
            mp3_filename = os.path.join(
                self.output_dir, f"recording_{timestamp_str}.mp3"
            )

            # ä¿å­˜ä¸ºWAVæ–‡ä»¶
            with wave.open(wav_filename, "wb") as wav_file:
                wav_file.setnchannels(CHANNELS)
                wav_file.setsampwidth(BIT_DEPTH // 8)
                wav_file.setframerate(SAMPLE_RATE)
                wav_file.writeframes(audio_data)

            # è½¬æ¢ä¸ºMP3
            audio = AudioSegment.from_wav(wav_filename)
            audio.export(mp3_filename, format="mp3", bitrate="128k")

            # åˆ é™¤ä¸´æ—¶WAVæ–‡ä»¶
            os.remove(wav_filename)

            # æ˜¾ç¤ºéŸ³é¢‘ä¿¡æ¯
            duration = len(audio_data) / BYTES_PER_SAMPLE / SAMPLE_RATE
            print(f"\nâœ… éŸ³é¢‘ä¿¡æ¯:")
            print(f"   æ—¶é•¿: {duration:.2f} ç§’")
            print(f"   å¤§å°: {len(audio_data) / 1024:.1f} KB")

            return mp3_filename

        except Exception as e:
            print(f"\nâŒ ä¿å­˜éŸ³é¢‘å¤±è´¥: {e}")
            return None

    async def save_response_audio(
        self, audio_data, timestamp, sample_rate=MODEL_SAMPLE_RATE
    ):
        """ä¿å­˜å“åº”éŸ³é¢‘æ•°æ®ä¸ºMP3æ–‡ä»¶"""
        if not audio_data:
            print("âš ï¸  æ²¡æœ‰å“åº”éŸ³é¢‘æ•°æ®å¯ä¿å­˜")
            return None

        try:
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp_str = (
                timestamp.strftime("%Y%m%d_%H%M%S")
                if timestamp
                else datetime.now().strftime("%Y%m%d_%H%M%S")
            )
            wav_filename = os.path.join(
                self.response_dir, f"response_{timestamp_str}.wav"
            )
            mp3_filename = os.path.join(
                self.response_dir, f"response_{timestamp_str}.mp3"
            )

            # ä¿å­˜ä¸ºWAVæ–‡ä»¶ï¼ˆä½¿ç”¨æ­£ç¡®çš„é‡‡æ ·ç‡ï¼‰
            with wave.open(wav_filename, "wb") as wav_file:
                wav_file.setnchannels(CHANNELS)
                wav_file.setsampwidth(BIT_DEPTH // 8)
                wav_file.setframerate(sample_rate)  # ä½¿ç”¨ä¼ å…¥çš„é‡‡æ ·ç‡
                wav_file.writeframes(audio_data)

            # è½¬æ¢ä¸ºMP3
            audio = AudioSegment.from_wav(wav_filename)
            audio.export(mp3_filename, format="mp3", bitrate="128k")

            # åˆ é™¤ä¸´æ—¶WAVæ–‡ä»¶
            os.remove(wav_filename)

            # æ˜¾ç¤ºéŸ³é¢‘ä¿¡æ¯
            duration = len(audio_data) / BYTES_PER_SAMPLE / sample_rate
            print(f"\nâœ… å“åº”éŸ³é¢‘ä¿¡æ¯:")
            print(f"   æ—¶é•¿: {duration:.2f} ç§’")
            print(f"   å¤§å°: {len(audio_data) / 1024:.1f} KB")
            print(f"   é‡‡æ ·ç‡: {sample_rate} Hz")

            return mp3_filename

        except Exception as e:
            print(f"\nâŒ ä¿å­˜å“åº”éŸ³é¢‘å¤±è´¥: {e}")
            return None

    def resample_audio(self, audio_data, from_rate, to_rate):
        """é‡é‡‡æ ·éŸ³é¢‘æ•°æ®"""
        if from_rate == to_rate:
            return audio_data

        try:
            import numpy as np
            from scipy import signal

            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
            audio_array = np.frombuffer(audio_data, dtype=np.int16)

            # è®¡ç®—é‡é‡‡æ ·åçš„é•¿åº¦
            num_samples = int(len(audio_array) * to_rate / from_rate)

            # ä½¿ç”¨scipyè¿›è¡Œé‡é‡‡æ ·
            resampled = signal.resample(audio_array, num_samples)

            # è½¬æ¢å›int16
            resampled = np.clip(resampled, -32768, 32767).astype(np.int16)

            # è½¬æ¢å›å­—èŠ‚æ•°æ®
            return resampled.tobytes()

        except ImportError:
            # å¦‚æœæ²¡æœ‰å®‰è£…scipyï¼Œä½¿ç”¨ç®€å•çš„çº¿æ€§æ’å€¼
            print("âš ï¸  æœªå®‰è£…scipyï¼Œä½¿ç”¨ç®€å•é‡é‡‡æ ·æ–¹æ³•")

            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸º16ä½æ•´æ•°æ•°ç»„
            audio_array = []
            for i in range(0, len(audio_data), 2):
                if i + 1 < len(audio_data):
                    sample = int.from_bytes(
                        audio_data[i : i + 2], byteorder="little", signed=True
                    )
                    audio_array.append(sample)

            # ç®€å•çš„é‡é‡‡æ ·
            ratio = to_rate / from_rate
            resampled = []
            for i in range(int(len(audio_array) * ratio)):
                src_idx = i / ratio
                src_idx_int = int(src_idx)
                src_idx_frac = src_idx - src_idx_int

                if src_idx_int + 1 < len(audio_array):
                    # çº¿æ€§æ’å€¼
                    sample = int(
                        audio_array[src_idx_int] * (1 - src_idx_frac)
                        + audio_array[src_idx_int + 1] * src_idx_frac
                    )
                else:
                    sample = audio_array[min(src_idx_int, len(audio_array) - 1)]

                resampled.append(sample)

            # è½¬æ¢å›å­—èŠ‚æ•°æ®
            result = bytearray()
            for sample in resampled:
                result.extend(sample.to_bytes(2, byteorder="little", signed=True))

            return bytes(result)

    async def start_server(self):
        """å¯åŠ¨WebSocketæœåŠ¡å™¨"""
        print("=" * 60)
        print("ESP32éŸ³é¢‘WebSocketæœåŠ¡å™¨")
        print("=" * 60)
        print(f"ç›‘å¬åœ°å€: ws://{WS_HOST}:{WS_PORT}")
        if self.use_model:
            print(f"å“åº”æ¨¡å¼: AIå¤§æ¨¡å‹ç”Ÿæˆå“åº”")
            print(f"æ¨¡å‹: qwen-omni-turbo-realtime")
        else:
            print(f"å“åº”æ¨¡å¼: é»˜è®¤éŸ³é¢‘ (light_on.h)")
            print(f"æç¤º: è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY ä»¥å¯ç”¨AIå“åº”")
        print("=" * 60)
        print("\nç­‰å¾…ESP32è¿æ¥...\n")

        # åˆ›å»ºWebSocketæœåŠ¡å™¨
        async with websockets.serve(self.handle_client, WS_HOST, WS_PORT):
            await asyncio.Future()  # æ°¸è¿œè¿è¡Œ


def main():
    server = WebSocketAudioServer()

    try:
        # è¿è¡ŒæœåŠ¡å™¨
        asyncio.run(server.start_server())
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æœåŠ¡å™¨å·²åœæ­¢")


if __name__ == "__main__":
    main()
