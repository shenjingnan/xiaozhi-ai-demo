#!/usr/bin/env python3
"""
ESP32éŸ³é¢‘WebSocketæœåŠ¡å™¨
é€šè¿‡WebSocketä¸ESP32åŒå‘é€šä¿¡
"""

import os
import sys
import json
import base64
import wave
import asyncio
import websockets
from datetime import datetime
from pydub import AudioSegment
import time

# å°è¯•å¯¼å…¥æœåŠ¡å™¨ç‰ˆæœ¬çš„å®¢æˆ·ç«¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸç‰ˆ
try:
    from examples.speech_commands_recognition_with_llm.server.omni_realtime_client import (
        OmniRealtimeClient,
        TurnDetectionMode,
    )

    OMNI_CLIENT_AVAILABLE = True
    print("âœ… ä½¿ç”¨æœåŠ¡å™¨ç‰ˆæœ¬çš„å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆä¼˜åŒ–æ—¥å¿—è¾“å‡ºï¼‰")
except ImportError:
    # æ·»åŠ model_demoç›®å½•åˆ°sys.path
    sys.path.append(os.path.join(os.path.dirname(__file__), "../model_demo"))
    try:
        from omni_realtime_client import OmniRealtimeClient, TurnDetectionMode

        OMNI_CLIENT_AVAILABLE = True
        print("âš ï¸  ä½¿ç”¨åŸç‰ˆå¤§æ¨¡å‹å®¢æˆ·ç«¯")
    except ImportError:
        print("âš ï¸  è­¦å‘Š: æ— æ³•å¯¼å…¥omni_realtime_clientï¼Œå°†ä½¿ç”¨é»˜è®¤éŸ³é¢‘å“åº”")
        OMNI_CLIENT_AVAILABLE = False

# éŸ³é¢‘å‚æ•°é…ç½®
SAMPLE_RATE = 16000  # ESP32ä½¿ç”¨çš„é‡‡æ ·ç‡ 16kHz
MODEL_SAMPLE_RATE = 24000  # å¤§æ¨¡å‹è¾“å‡ºçš„é‡‡æ ·ç‡ 24kHz
CHANNELS = 1  # å•å£°é“
BIT_DEPTH = 16  # 16ä½
BYTES_PER_SAMPLE = 2  # 16ä½ = 2å­—èŠ‚

# WebSocketæœåŠ¡å™¨é…ç½®
WS_HOST = "0.0.0.0"  # ç›‘å¬æ‰€æœ‰æ¥å£
WS_PORT = 8888  # WebSocketç«¯å£


class WebSocketAudioServer:
    """WebSocketéŸ³é¢‘æœåŠ¡å™¨"""

    def __init__(self):
        self.output_dir = os.path.join(os.path.dirname(__file__), "user_records")
        self.response_dir = os.path.join(os.path.dirname(__file__), "response_records")
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.response_dir, exist_ok=True)

        # åˆå§‹åŒ–Omni Realtimeå®¢æˆ·ç«¯
        self.api_key = os.environ.get("DASHSCOPE_API_KEY")
        if not self.api_key or not OMNI_CLIENT_AVAILABLE:
            if not self.api_key:
                print(
                    "âš ï¸  è­¦å‘Š: æœªè®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡ï¼Œå°†ä½¿ç”¨é»˜è®¤light_onéŸ³é¢‘"
                )
            self.use_model = False
        else:
            self.use_model = True
            print("âœ… å·²é…ç½®å¤§æ¨¡å‹APIï¼Œå°†ä½¿ç”¨AIç”Ÿæˆå“åº”éŸ³é¢‘")


    async def handle_client(self, websocket, path):
        """å¤„ç†å®¢æˆ·ç«¯è¿æ¥"""
        client_ip = websocket.remote_address[0]
        print(f"\nğŸ”— æ–°çš„å®¢æˆ·ç«¯è¿æ¥: {client_ip}")
        
        # å®¢æˆ·ç«¯çŠ¶æ€
        client_state = {
            'is_recording': False,
            'realtime_client': None,
            'message_task': None,
            'audio_buffer': bytearray(),
            'audio_tracker': {'total_sent': 0, 'last_time': time.time()}
        }

        try:
            async for message in websocket:
                try:
                    # æ£€æŸ¥æ¶ˆæ¯ç±»å‹
                    if isinstance(message, bytes):
                        # äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ® - å®æ—¶è½¬å‘åˆ°LLM
                        if client_state['is_recording'] and client_state['realtime_client']:
                            # æ·»åŠ åˆ°ç¼“å†²åŒºï¼ˆç”¨äºä¿å­˜ï¼‰
                            client_state['audio_buffer'].extend(message)
                            
                            # å®æ—¶è½¬å‘åˆ°LLM
                            encoded_data = base64.b64encode(message).decode("utf-8")
                            event = {
                                "event_id": "event_" + str(int(time.time() * 1000)),
                                "type": "input_audio_buffer.append",
                                "audio": encoded_data,
                            }
                            await client_state['realtime_client'].send_event(event)
                            print(f"   å®æ—¶è½¬å‘éŸ³é¢‘å—: {len(message)} å­—èŠ‚")
                        continue

                    # è§£æJSONæ¶ˆæ¯
                    data = json.loads(message)
                    event = data.get("event")

                    if event == "wake_word_detected":
                        print(f"ğŸ‰ [{client_ip}] æ£€æµ‹åˆ°å”¤é†’è¯ï¼")
                        
                    elif event == "recording_started":
                        print(f"ğŸ¤ [{client_ip}] å¼€å§‹å½•éŸ³...")
                        client_state['is_recording'] = True
                        client_state['audio_buffer'] = bytearray()
                        client_state['audio_tracker'] = {'total_sent': 0, 'last_time': time.time()}
                        
                        # åˆå§‹åŒ–LLMè¿æ¥
                        if self.use_model:
                            try:
                                # åˆ›å»ºå¤§æ¨¡å‹å®¢æˆ·ç«¯
                                client_state['realtime_client'] = OmniRealtimeClient(
                                    base_url="wss://dashscope.aliyuncs.com/api-ws/v1/realtime",
                                    api_key=self.api_key,
                                    model="qwen-omni-turbo-realtime-2025-05-08",
                                    voice="Chelsie",
                                    on_audio_delta=lambda audio: asyncio.create_task(
                                        self.on_audio_delta_handler(websocket, client_ip, audio, client_state['audio_tracker'])
                                    ),
                                    turn_detection_mode=TurnDetectionMode.MANUAL,
                                )
                                
                                # è¿æ¥åˆ°å¤§æ¨¡å‹
                                await client_state['realtime_client'].connect()
                                
                                # å¯åŠ¨æ¶ˆæ¯å¤„ç†
                                client_state['message_task'] = asyncio.create_task(
                                    client_state['realtime_client'].handle_messages()
                                )
                                
                                print(f"âœ… [{client_ip}] LLMè¿æ¥æˆåŠŸï¼Œå‡†å¤‡æ¥æ”¶å®æ—¶éŸ³é¢‘")
                                
                            except Exception as e:
                                print(f"âŒ [{client_ip}] åˆå§‹åŒ–å¤§æ¨¡å‹å¤±è´¥: {e}")
                                client_state['realtime_client'] = None
                    
                    elif event == "recording_ended":
                        print(f"âœ… [{client_ip}] å½•éŸ³ç»“æŸ")
                        client_state['is_recording'] = False
                        
                        # ä¿å­˜éŸ³é¢‘
                        if len(client_state['audio_buffer']) > 0:
                            print(f"ğŸ“Š [{client_ip}] éŸ³é¢‘æ€»å¤§å°: {len(client_state['audio_buffer'])} å­—èŠ‚ ({len(client_state['audio_buffer'])/2/SAMPLE_RATE:.2f}ç§’)")
                            
                            # ä¿å­˜éŸ³é¢‘
                            current_timestamp = datetime.now()
                            saved_file = await self.save_audio([bytes(client_state['audio_buffer'])], current_timestamp)
                            if saved_file:
                                print(f"âœ… [{client_ip}] éŸ³é¢‘å·²ä¿å­˜: {saved_file}")
                        
                        # è§¦å‘LLMå“åº”ç”Ÿæˆ
                        if self.use_model and client_state['realtime_client']:
                            try:
                                # æ‰‹åŠ¨è§¦å‘å“åº”ç”Ÿæˆ
                                await client_state['realtime_client'].create_response()
                                
                                # ç­‰å¾…å“åº”å®Œæˆï¼ˆæœ€å¤š30ç§’ï¼‰
                                print(f"ğŸ¤– [{client_ip}] ç­‰å¾…æ¨¡å‹ç”Ÿæˆå“åº”...")
                                max_wait_time = 30
                                start_time = time.time()
                                
                                while time.time() - start_time < max_wait_time:
                                    await asyncio.sleep(0.1)
                                    
                                    # å¦‚æœè¶…è¿‡2ç§’æ²¡æœ‰æ–°çš„éŸ³é¢‘æ•°æ®å‘é€ï¼Œè®¤ä¸ºå“åº”ç»“æŸ
                                    if client_state['audio_tracker']['total_sent'] > 0 and \
                                       time.time() - client_state['audio_tracker']['last_time'] > 2.0:
                                        print(f"âœ… [{client_ip}] å“åº”éŸ³é¢‘å‘é€å®Œæˆï¼Œæ€»è®¡: {client_state['audio_tracker']['total_sent']} å­—èŠ‚")
                                        break
                                
                                # å¦‚æœæ²¡æœ‰æ”¶åˆ°ä»»ä½•éŸ³é¢‘å“åº”ï¼Œåªæ‰“å°è­¦å‘Š
                                if client_state['audio_tracker']['total_sent'] == 0:
                                    print(f"âš ï¸ [{client_ip}] æœªæ”¶åˆ°å¤§æ¨¡å‹å“åº”")
                                
                                # å‘é€pingä½œä¸ºéŸ³é¢‘ç»“æŸæ ‡å¿—
                                await websocket.ping()
                                
                            except Exception as e:
                                print(f"âŒ [{client_ip}] æ¨¡å‹å¤„ç†å¤±è´¥: {e}")
                        else:
                            # ä¸ä½¿ç”¨æ¨¡å‹æ—¶åªæ‰“å°è­¦å‘Š
                            print(f"âš ï¸ [{client_ip}] æœªå¯ç”¨AIæ¨¡å‹ï¼Œæ— æ³•ç”Ÿæˆå“åº”")
                    
                    elif event == "recording_cancelled":
                        print(f"âš ï¸ [{client_ip}] å½•éŸ³å–æ¶ˆ")
                        client_state['is_recording'] = False
                        client_state['audio_buffer'] = bytearray()

                except json.JSONDecodeError as e:
                    print(f"âŒ [{client_ip}] JSONè§£æé”™è¯¯: {e}")
                except Exception as e:
                    print(f"âŒ [{client_ip}] å¤„ç†æ¶ˆæ¯é”™è¯¯: {e}")

        except websockets.exceptions.ConnectionClosed:
            print(f"ğŸ”Œ [{client_ip}] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
        except Exception as e:
            print(f"âŒ [{client_ip}] è¿æ¥é”™è¯¯: {e}")
        finally:
            # æ¸…ç†èµ„æº
            if client_state['realtime_client']:
                try:
                    if client_state['message_task']:
                        client_state['message_task'].cancel()
                    await client_state['realtime_client'].close()
                except:
                    pass

    # åˆ é™¤ä¸å†éœ€è¦çš„process_streaming_audio_with_first_messageæ–¹æ³•
    
    async def on_audio_delta_handler(self, websocket, client_ip, audio_data, audio_tracker):
        """å¤„ç†æ¨¡å‹è¿”å›çš„éŸ³é¢‘ç‰‡æ®µ"""
        try:
            # ç›´æ¥é‡é‡‡æ ·å¹¶å‘é€éŸ³é¢‘æ•°æ®
            resampled = self.resample_audio(
                audio_data, MODEL_SAMPLE_RATE, SAMPLE_RATE
            )
            
            # ç«‹å³å‘é€åˆ°ESP32
            await websocket.send(resampled)
            print(f"   â†’ æµå¼å‘é€éŸ³é¢‘å—: {len(resampled)} å­—èŠ‚")
            
            # æ›´æ–°éŸ³é¢‘è·Ÿè¸ªä¿¡æ¯
            audio_tracker['total_sent'] += len(resampled)
            audio_tracker['last_time'] = time.time()
            
        except Exception as e:
            print(f"âŒ [{client_ip}] å‘é€éŸ³é¢‘å—å¤±è´¥: {e}")
    
    async def process_streaming_audio(self, websocket, client_ip):
        """å¤„ç†æµå¼éŸ³é¢‘æ•°æ®"""
        print(f"ğŸ¤ [{client_ip}] å¼€å§‹æ¥æ”¶æµå¼éŸ³é¢‘æ•°æ®...")
        
        # éŸ³é¢‘æ•°æ®ç¼“å†²åŒº
        audio_buffer = bytearray()
        
        # ç­‰å¾…éŸ³é¢‘æ•°æ®
        while True:
            try:
                # æ¥æ”¶æ•°æ®ï¼ˆè®¾ç½®è¶…æ—¶ï¼‰
                message = await asyncio.wait_for(websocket.recv(), timeout=5.0)
                
                if isinstance(message, bytes):
                    # äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
                    audio_buffer.extend(message)
                    print(f"   æ”¶åˆ°éŸ³é¢‘å—: {len(message)} å­—èŠ‚, æ€»è®¡: {len(audio_buffer)} å­—èŠ‚")
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç»æ”¶åˆ°è¶³å¤Ÿçš„æ•°æ®ï¼ˆä¾‹å¦‚è¶…è¿‡1ç§’ï¼‰
                    if len(audio_buffer) >= SAMPLE_RATE * 2:  # 1ç§’çš„éŸ³é¢‘æ•°æ®
                        # å¯ä»¥å¼€å§‹å¤„ç†äº†
                        break
                else:
                    # éäºŒè¿›åˆ¶æ¶ˆæ¯ï¼Œå¯èƒ½æ˜¯æ§åˆ¶æ¶ˆæ¯
                    break
                    
            except asyncio.TimeoutError:
                # è¶…æ—¶ï¼Œè®¤ä¸ºéŸ³é¢‘æ¥æ”¶å®Œæˆ
                print(f"â° [{client_ip}] éŸ³é¢‘æ¥æ”¶è¶…æ—¶ï¼Œå‡†å¤‡å¤„ç†")
                break
            except Exception as e:
                print(f"âŒ [{client_ip}] æ¥æ”¶éŸ³é¢‘æ•°æ®å¤±è´¥: {e}")
                break
        
        if len(audio_buffer) > 0:
            print(f"âœ… [{client_ip}] éŸ³é¢‘æ¥æ”¶å®Œæˆï¼Œæ€»å¤§å°: {len(audio_buffer)} å­—èŠ‚ ({len(audio_buffer)/2/SAMPLE_RATE:.2f}ç§’)")
            
            # ä¿å­˜éŸ³é¢‘
            current_timestamp = datetime.now()
            saved_file = await self.save_audio([bytes(audio_buffer)], current_timestamp)
            if saved_file:
                print(f"âœ… [{client_ip}] éŸ³é¢‘å·²ä¿å­˜: {saved_file}")
            
            # ç­‰å¾…ä¸€ä¸‹å†å‘é€å“åº”
            print(f"â³ [{client_ip}] ç­‰å¾…0.5ç§’åå‘é€å“åº”éŸ³é¢‘...")
            await asyncio.sleep(0.5)
            
            # å‘é€å“åº”éŸ³é¢‘
            if self.use_model:
                await self.send_model_response_audio(websocket, client_ip, bytes(audio_buffer))
            else:
                print(f"âš ï¸ [{client_ip}] æœªå¯ç”¨AIæ¨¡å‹ï¼Œæ— æ³•ç”Ÿæˆå“åº”")
        else:
            print(f"âš ï¸ [{client_ip}] æ²¡æœ‰æ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®")
    
    async def send_model_response_audio(self, websocket, client_ip, user_audio_data):
        """ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆå¹¶å‘é€å“åº”éŸ³é¢‘ï¼ˆæµå¼ï¼‰"""
        print(f"ğŸ¤– [{client_ip}] ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆå“åº”éŸ³é¢‘ï¼ˆæµå¼ï¼‰...")

        try:
            total_audio_sent = 0
            stream_complete = False
            last_sent_time = time.time()
            
            # å®šä¹‰æµå¼éŸ³é¢‘å¤„ç†å‡½æ•°
            async def on_audio_delta(audio_data):
                """ç›´æ¥å¤„ç†å¹¶å‘é€éŸ³é¢‘ç‰‡æ®µåˆ°ESP32"""
                nonlocal total_audio_sent, last_sent_time
                try:
                    # ç›´æ¥é‡é‡‡æ ·å¹¶å‘é€éŸ³é¢‘æ•°æ®
                    # audio_data æ˜¯ 24kHz çš„éŸ³é¢‘æ•°æ®ï¼Œéœ€è¦è½¬æ¢ä¸º 16kHz
                    resampled = self.resample_audio(
                        audio_data, MODEL_SAMPLE_RATE, SAMPLE_RATE
                    )
                    
                    # ç«‹å³å‘é€åˆ°ESP32
                    await websocket.send(resampled)
                    total_audio_sent += len(resampled)
                    last_sent_time = time.time()  # æ›´æ–°æœ€åå‘é€æ—¶é—´
                    print(f"   â†’ æµå¼å‘é€éŸ³é¢‘å—: {len(resampled)} å­—èŠ‚")
                    
                except Exception as e:
                    print(f"âŒ [{client_ip}] å‘é€éŸ³é¢‘å—å¤±è´¥: {e}")

            # åˆ›å»ºå¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆå‚è€ƒqwen_demo.pyçš„å®ç°ï¼‰
            realtime_client = OmniRealtimeClient(
                base_url="wss://dashscope.aliyuncs.com/api-ws/v1/realtime",
                api_key=self.api_key,
                model="qwen-omni-turbo-realtime-2025-05-08",
                voice="Chelsie",
                on_audio_delta=lambda audio: asyncio.create_task(on_audio_delta(audio)),
                turn_detection_mode=TurnDetectionMode.MANUAL,  # ä½¿ç”¨æ‰‹åŠ¨æ¨¡å¼ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦æ§åˆ¶ä½•æ—¶ç”Ÿæˆå“åº”
            )

            # è¿æ¥åˆ°å¤§æ¨¡å‹
            await realtime_client.connect()

            # å¯åŠ¨æ¶ˆæ¯å¤„ç†
            message_task = asyncio.create_task(realtime_client.handle_messages())

            # å‘é€ç”¨æˆ·éŸ³é¢‘æ•°æ®
            print(f"   å‘é€ç”¨æˆ·éŸ³é¢‘åˆ°å¤§æ¨¡å‹: {len(user_audio_data)} å­—èŠ‚")

            # å°†éŸ³é¢‘æ•°æ®åˆ†å—å‘é€ï¼ˆå‚è€ƒmain.pyçš„å®ç°ï¼‰
            chunk_size = 3200  # æ¯ä¸ªå—200msçš„éŸ³é¢‘æ•°æ®ï¼ˆ16kHz * 2å­—èŠ‚ * 0.2ç§’ï¼‰
            for i in range(0, len(user_audio_data), chunk_size):
                chunk = user_audio_data[i : i + chunk_size]
                # Base64ç¼–ç éŸ³é¢‘æ•°æ®
                encoded_data = base64.b64encode(chunk).decode("utf-8")

                # æ„å»ºäº‹ä»¶ï¼ˆå‚è€ƒmain.pyçš„æ ¼å¼ï¼‰
                event = {
                    "event_id": "event_" + str(int(time.time() * 1000)),
                    "type": "input_audio_buffer.append",
                    "audio": encoded_data,
                }
                await realtime_client.send_event(event)

                # å°å»¶è¿Ÿé¿å…è¿‡å¿«å‘é€
                await asyncio.sleep(0.01)

            # æ‰‹åŠ¨è§¦å‘å“åº”ç”Ÿæˆ
            await realtime_client.create_response()

            # ç­‰å¾…å“åº”ç”Ÿæˆå’Œå‘é€å®Œæˆ
            max_wait_time = 30  # æœ€å¤šç­‰å¾…30ç§’
            start_time = time.time()
            
            while time.time() - start_time < max_wait_time:
                await asyncio.sleep(0.1)
                
                # å¦‚æœè¶…è¿‡1ç§’æ²¡æœ‰æ–°çš„éŸ³é¢‘æ•°æ®å‘é€ï¼Œè®¤ä¸ºæµç»“æŸ
                if total_audio_sent > 0 and time.time() - last_sent_time > 1.0:
                    stream_complete = True
                    break
            
            # å‘é€pingä½œä¸ºéŸ³é¢‘ç»“æŸæ ‡å¿—
            await websocket.ping()
            
            # å–æ¶ˆæ¶ˆæ¯ä»»åŠ¡å¹¶å…³é—­è¿æ¥
            try:
                message_task.cancel()
                await message_task
            except asyncio.CancelledError:
                pass
            await realtime_client.close()
            
            if total_audio_sent > 0:
                print(f"âœ… [{client_ip}] æµå¼éŸ³é¢‘å‘é€å®Œæˆï¼Œæ€»è®¡: {total_audio_sent} å­—èŠ‚ ({total_audio_sent/2/SAMPLE_RATE:.2f}ç§’)")
            else:
                print(f"âš ï¸  [{client_ip}] æœªæ”¶åˆ°å¤§æ¨¡å‹å“åº”")

        except Exception as e:
            print(f"âŒ [{client_ip}] å¤§æ¨¡å‹å¤„ç†å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()


    async def save_audio(self, audio_buffer, timestamp):
        """ä¿å­˜éŸ³é¢‘æ•°æ®ä¸ºMP3æ–‡ä»¶"""
        if not audio_buffer:
            print("âš ï¸  æ²¡æœ‰éŸ³é¢‘æ•°æ®å¯ä¿å­˜")
            return None

        try:
            # åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ•°æ®
            audio_data = b"".join(audio_buffer)

            # ç”Ÿæˆæ–‡ä»¶å
            timestamp_str = (
                timestamp.strftime("%Y%m%d_%H%M%S")
                if timestamp
                else datetime.now().strftime("%Y%m%d_%H%M%S")
            )
            wav_filename = os.path.join(
                self.output_dir, f"recording_{timestamp_str}.wav"
            )
            mp3_filename = os.path.join(
                self.output_dir, f"recording_{timestamp_str}.mp3"
            )

            # ä¿å­˜ä¸ºWAVæ–‡ä»¶
            with wave.open(wav_filename, "wb") as wav_file:
                wav_file.setnchannels(CHANNELS)
                wav_file.setsampwidth(BIT_DEPTH // 8)
                wav_file.setframerate(SAMPLE_RATE)
                wav_file.writeframes(audio_data)

            # è½¬æ¢ä¸ºMP3
            audio = AudioSegment.from_wav(wav_filename)
            audio.export(mp3_filename, format="mp3", bitrate="128k")

            # åˆ é™¤ä¸´æ—¶WAVæ–‡ä»¶
            os.remove(wav_filename)

            # æ˜¾ç¤ºéŸ³é¢‘ä¿¡æ¯
            duration = len(audio_data) / BYTES_PER_SAMPLE / SAMPLE_RATE
            print(f"\nâœ… éŸ³é¢‘ä¿¡æ¯:")
            print(f"   æ—¶é•¿: {duration:.2f} ç§’")
            print(f"   å¤§å°: {len(audio_data) / 1024:.1f} KB")

            return mp3_filename

        except Exception as e:
            print(f"\nâŒ ä¿å­˜éŸ³é¢‘å¤±è´¥: {e}")
            return None

    async def save_response_audio(
        self, audio_data, timestamp, sample_rate=MODEL_SAMPLE_RATE
    ):
        """ä¿å­˜å“åº”éŸ³é¢‘æ•°æ®ä¸ºMP3æ–‡ä»¶"""
        if not audio_data:
            print("âš ï¸  æ²¡æœ‰å“åº”éŸ³é¢‘æ•°æ®å¯ä¿å­˜")
            return None

        try:
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp_str = (
                timestamp.strftime("%Y%m%d_%H%M%S")
                if timestamp
                else datetime.now().strftime("%Y%m%d_%H%M%S")
            )
            wav_filename = os.path.join(
                self.response_dir, f"response_{timestamp_str}.wav"
            )
            mp3_filename = os.path.join(
                self.response_dir, f"response_{timestamp_str}.mp3"
            )

            # ä¿å­˜ä¸ºWAVæ–‡ä»¶ï¼ˆä½¿ç”¨æ­£ç¡®çš„é‡‡æ ·ç‡ï¼‰
            with wave.open(wav_filename, "wb") as wav_file:
                wav_file.setnchannels(CHANNELS)
                wav_file.setsampwidth(BIT_DEPTH // 8)
                wav_file.setframerate(sample_rate)  # ä½¿ç”¨ä¼ å…¥çš„é‡‡æ ·ç‡
                wav_file.writeframes(audio_data)

            # è½¬æ¢ä¸ºMP3
            audio = AudioSegment.from_wav(wav_filename)
            audio.export(mp3_filename, format="mp3", bitrate="128k")

            # åˆ é™¤ä¸´æ—¶WAVæ–‡ä»¶
            os.remove(wav_filename)

            # æ˜¾ç¤ºéŸ³é¢‘ä¿¡æ¯
            duration = len(audio_data) / BYTES_PER_SAMPLE / sample_rate
            print(f"\nâœ… å“åº”éŸ³é¢‘ä¿¡æ¯:")
            print(f"   æ—¶é•¿: {duration:.2f} ç§’")
            print(f"   å¤§å°: {len(audio_data) / 1024:.1f} KB")
            print(f"   é‡‡æ ·ç‡: {sample_rate} Hz")

            return mp3_filename

        except Exception as e:
            print(f"\nâŒ ä¿å­˜å“åº”éŸ³é¢‘å¤±è´¥: {e}")
            return None

    def resample_audio(self, audio_data, from_rate, to_rate):
        """é‡é‡‡æ ·éŸ³é¢‘æ•°æ®"""
        if from_rate == to_rate:
            return audio_data

        try:
            import numpy as np
            from scipy import signal

            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
            audio_array = np.frombuffer(audio_data, dtype=np.int16)

            # è®¡ç®—é‡é‡‡æ ·åçš„é•¿åº¦
            num_samples = int(len(audio_array) * to_rate / from_rate)

            # ä½¿ç”¨scipyè¿›è¡Œé‡é‡‡æ ·
            resampled = signal.resample(audio_array, num_samples)

            # è½¬æ¢å›int16
            resampled = np.clip(resampled, -32768, 32767).astype(np.int16)

            # è½¬æ¢å›å­—èŠ‚æ•°æ®
            return resampled.tobytes()

        except ImportError:
            # å¦‚æœæ²¡æœ‰å®‰è£…scipyï¼Œä½¿ç”¨ç®€å•çš„çº¿æ€§æ’å€¼
            print("âš ï¸  æœªå®‰è£…scipyï¼Œä½¿ç”¨ç®€å•é‡é‡‡æ ·æ–¹æ³•")

            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸º16ä½æ•´æ•°æ•°ç»„
            audio_array = []
            for i in range(0, len(audio_data), 2):
                if i + 1 < len(audio_data):
                    sample = int.from_bytes(
                        audio_data[i : i + 2], byteorder="little", signed=True
                    )
                    audio_array.append(sample)

            # ç®€å•çš„é‡é‡‡æ ·
            ratio = to_rate / from_rate
            resampled = []
            for i in range(int(len(audio_array) * ratio)):
                src_idx = i / ratio
                src_idx_int = int(src_idx)
                src_idx_frac = src_idx - src_idx_int

                if src_idx_int + 1 < len(audio_array):
                    # çº¿æ€§æ’å€¼
                    sample = int(
                        audio_array[src_idx_int] * (1 - src_idx_frac)
                        + audio_array[src_idx_int + 1] * src_idx_frac
                    )
                else:
                    sample = audio_array[min(src_idx_int, len(audio_array) - 1)]

                resampled.append(sample)

            # è½¬æ¢å›å­—èŠ‚æ•°æ®
            result = bytearray()
            for sample in resampled:
                result.extend(sample.to_bytes(2, byteorder="little", signed=True))

            return bytes(result)

    async def start_server(self):
        """å¯åŠ¨WebSocketæœåŠ¡å™¨"""
        print("=" * 60)
        print("ESP32éŸ³é¢‘WebSocketæœåŠ¡å™¨")
        print("=" * 60)
        print(f"ç›‘å¬åœ°å€: ws://{WS_HOST}:{WS_PORT}")
        if self.use_model:
            print(f"å“åº”æ¨¡å¼: AIå¤§æ¨¡å‹ç”Ÿæˆå“åº”")
            print(f"æ¨¡å‹: qwen-omni-turbo-realtime")
        else:
            print(f"å“åº”æ¨¡å¼: æœªå¯ç”¨ï¼ˆéœ€è¦è®¾ç½® DASHSCOPE_API_KEYï¼‰")
            print(f"æç¤º: è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY ä»¥å¯ç”¨AIå“åº”")
        print("=" * 60)
        print("\nç­‰å¾…ESP32è¿æ¥...\n")

        # åˆ›å»ºWebSocketæœåŠ¡å™¨
        async with websockets.serve(self.handle_client, WS_HOST, WS_PORT):
            await asyncio.Future()  # æ°¸è¿œè¿è¡Œ


def main():
    server = WebSocketAudioServer()

    try:
        # è¿è¡ŒæœåŠ¡å™¨
        asyncio.run(server.start_server())
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æœåŠ¡å™¨å·²åœæ­¢")


if __name__ == "__main__":
    main()
