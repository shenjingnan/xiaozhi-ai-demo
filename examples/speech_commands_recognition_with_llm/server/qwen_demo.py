# -- coding: utf-8 --
"""
æŒ‰é”®è§¦å‘å½•éŸ³ï¼Œè‡ªåŠ¨æ£€æµ‹ç»“æŸçš„ç‰ˆæœ¬
æŒ‰ä¸€ä¸‹ '1' å¼€å§‹å½•éŸ³ï¼ŒLLMè‡ªåŠ¨æ£€æµ‹è¯´è¯ç»“æŸå¹¶å›å¤
"""
import os, time, base64, asyncio
from omni_realtime_client import OmniRealtimeClient, TurnDetectionMode
import pyaudio
import queue
import threading
from pynput import keyboard
import sys

# åˆ›å»ºä¸€ä¸ªå…¨å±€éŸ³é¢‘é˜Ÿåˆ—å’Œæ’­æ”¾çº¿ç¨‹
audio_queue = queue.Queue()
audio_player = None

# åˆå§‹åŒ–PyAudio
p = pyaudio.PyAudio()
RATE = 16000  # é‡‡æ ·ç‡ 16kHz
CHUNK = 3200  # æ¯ä¸ªéŸ³é¢‘å—çš„å¤§å°
FORMAT = pyaudio.paInt16  # 16ä½PCMæ ¼å¼
CHANNELS = 1  # å•å£°é“

# å½•éŸ³æ§åˆ¶æ ‡å¿—
is_recording = False
recording_lock = threading.Lock()
should_start_recording = False  # æ–°å¢ï¼šæ ‡è®°æ˜¯å¦åº”è¯¥å¼€å§‹å½•éŸ³
current_status = "ğŸ‘‚"  # å½“å‰çŠ¶æ€æ˜¾ç¤º
is_processing = False  # æ ‡è®°æ˜¯å¦æ­£åœ¨å¤„ç†å“åº”

def audio_player_thread():
    """åå°çº¿ç¨‹ç”¨äºæ’­æ”¾éŸ³é¢‘æ•°æ®"""
    stream = p.open(format=FORMAT,
                    channels=CHANNELS,
                    rate=24000,
                    output=True,
                    frames_per_buffer=CHUNK)
    
    try:
        while True:
            try:
                # ä»é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®
                audio_data = audio_queue.get(block=True, timeout=0.5)
                if audio_data is None:  # ç»“æŸä¿¡å·
                    break
                # æ’­æ”¾éŸ³é¢‘æ•°æ®
                stream.write(audio_data)
                audio_queue.task_done()
            except queue.Empty:
                # å¦‚æœé˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­ç­‰å¾…
                continue
    finally:
        # æ¸…ç†
        stream.stop_stream()
        stream.close()

def start_audio_player():
    """å¯åŠ¨éŸ³é¢‘æ’­æ”¾çº¿ç¨‹"""
    global audio_player
    if audio_player is None or not audio_player.is_alive():
        audio_player = threading.Thread(target=audio_player_thread, daemon=True)
        audio_player.start()

def handle_audio_data(audio_data):
    """å¤„ç†æ¥æ”¶åˆ°çš„éŸ³é¢‘æ•°æ®"""
    # å°†éŸ³é¢‘æ•°æ®æ”¾å…¥é˜Ÿåˆ—
    audio_queue.put(audio_data)

def on_press(key):
    """æŒ‰é”®æŒ‰ä¸‹äº‹ä»¶ - æŒ‰ä¸€ä¸‹ '1' å¼€å§‹å½•éŸ³"""
    global should_start_recording, is_recording, is_processing
    try:
        if hasattr(key, 'char') and key.char == '1':
            with recording_lock:
                # åªæœ‰åœ¨ä¸å½•éŸ³ä¸”ä¸å¤„ç†çš„çŠ¶æ€ä¸‹æ‰èƒ½å¼€å§‹æ–°å½•éŸ³
                if not is_recording and not is_processing:
                    should_start_recording = True
        # ESCé”®é€€å‡º
        elif key == keyboard.Key.esc:
            return False
    except AttributeError:
        pass

def update_status_line(message):
    """æ›´æ–°çŠ¶æ€è¡Œï¼ˆè¦†ç›–åŒä¸€è¡Œï¼‰"""
    print(f"\r{message}                    ", end="", flush=True)

async def handle_recording_trigger(client: OmniRealtimeClient):
    """å¤„ç†å½•éŸ³è§¦å‘çš„å¼‚æ­¥ä»»åŠ¡"""
    global is_recording, should_start_recording, current_status, is_processing
    
    while True:
        with recording_lock:
            if should_start_recording and not is_recording and not is_processing:
                should_start_recording = False
                is_recording = True
                current_status = "ğŸ™ï¸"
                update_status_line(f"{current_status} æ­£åœ¨å½•éŸ³ï¼Œè¯·è¯´è¯...")
                
                # æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº
                eventd = {
                    "event_id": "event_" + str(int(time.time() * 1000)),
                    "type": "input_audio_buffer.clear"
                }
                await client.send_event(eventd)
        
        await asyncio.sleep(0.05)  # 50ms æ£€æŸ¥ä¸€æ¬¡

async def microphone_streaming(client: OmniRealtimeClient):
    """éº¦å…‹é£å½•éŸ³æµå¼ä¼ è¾“"""
    CHUNK = 3200
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    
    p_local = pyaudio.PyAudio()
    stream = p_local.open(format=FORMAT,
                    channels=CHANNELS,
                    rate=RATE,
                    input=True,
                    frames_per_buffer=CHUNK)
    
    try:
        print("\nğŸ“Œ ä½¿ç”¨è¯´æ˜ï¼š")
        print("- æŒ‰ '1' é”®å¼€å§‹å½•éŸ³ ğŸ™ï¸")
        print("- è¯´è¯ç»“æŸåè‡ªåŠ¨è¯†åˆ«å¹¶å›å¤")
        print("- å›å¤å®Œæˆåå¯å†æ¬¡æŒ‰ '1' å¼€å§‹æ–°å¯¹è¯")
        print("- æŒ‰ 'ESC' é”®é€€å‡ºç¨‹åº\n")
        update_status_line(f"{current_status} å°±ç»ªï¼ŒæŒ‰ '1' å¼€å§‹å¯¹è¯")
        
        while True:
            with recording_lock:
                if is_recording:
                    try:
                        # è¯»å–éŸ³é¢‘æ•°æ®
                        audio_data = stream.read(CHUNK, exception_on_overflow=False)
                        encoded_data = base64.b64encode(audio_data).decode('utf-8')
                        
                        # å‘é€éŸ³é¢‘æ•°æ®åˆ°æœåŠ¡å™¨
                        eventd = {
                            "event_id": "event_" + str(int(time.time() * 1000)),
                            "type": "input_audio_buffer.append",
                            "audio": encoded_data
                        }
                        await client.send_event(eventd)
                    except Exception as e:
                        print(f"\nå½•éŸ³é”™è¯¯: {e}")
                        update_status_line(f"{current_status} å°±ç»ªï¼ŒæŒ‰ '1' å¼€å§‹å¯¹è¯")
            
            await asyncio.sleep(0.01)  # 10ms é—´éš”ï¼Œæ›´ä½å»¶è¿Ÿ
    finally:
        stream.stop_stream()
        stream.close()
        p_local.terminate()

async def main():
    global is_recording, is_processing, current_status
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.environ.get("DASHSCOPE_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY")
        print("export DASHSCOPE_API_KEY='your-api-key'")
        return
    
    # å¯åŠ¨éŸ³é¢‘æ’­æ”¾çº¿ç¨‹
    start_audio_player()
    
    # å¯åŠ¨é”®ç›˜ç›‘å¬å™¨ï¼Œä½¿ç”¨suppress=Trueæ¥é˜»æ­¢æŒ‰é”®ä¼ é€’åˆ°ç»ˆç«¯
    listener = keyboard.Listener(
        on_press=on_press,
        suppress=True  # é˜»æ­¢æŒ‰é”®ä¼ é€’åˆ°ç»ˆç«¯
    )
    listener.start()
    
    # å®šä¹‰å›è°ƒå‡½æ•°
    def on_text_output(text):
        """å¤„ç†æ–‡æœ¬è¾“å‡º"""
        print(f"\nğŸ’¬ AI: {text}", end="", flush=True)
    
    def on_input_done(text):
        """å¤„ç†è¾“å…¥è½¬å½•å®Œæˆ - è¡¨ç¤ºVADæ£€æµ‹åˆ°è¯´è¯ç»“æŸ"""
        global is_recording, is_processing, current_status
        if text.strip():  # å¦‚æœæœ‰æœ‰æ•ˆè¾“å…¥
            print(f"\nğŸ¤ è¯†åˆ«: {text}")
            with recording_lock:
                is_recording = False
                is_processing = True
                current_status = "â³"
            update_status_line(f"{current_status} æ€è€ƒä¸­...")
    
    def on_output_done(text):
        """å¤„ç†è¾“å‡ºå®Œæˆ"""
        global is_processing, current_status
        with recording_lock:
            is_processing = False
            current_status = "ğŸ‘‚"
        print("\nâœ… å›å¤å®Œæˆ")
        update_status_line(f"{current_status} å°±ç»ªï¼ŒæŒ‰ '1' å¼€å§‹æ–°å¯¹è¯")
    
    # æ·»åŠ é¢å¤–çš„äº‹ä»¶å¤„ç†å™¨
    extra_handlers = {
        "input_audio_buffer.speech_started": lambda data: print("\nğŸ”Š æ£€æµ‹åˆ°è¯´è¯..."),
        "input_audio_buffer.speech_stopped": lambda data: update_status_line("ğŸ¤” åˆ†æä¸­..."),
        "response.done": lambda data: on_output_done("")
    }
    
    # é…ç½®å®æ—¶å®¢æˆ·ç«¯
    realtime_client = OmniRealtimeClient(
        base_url="wss://dashscope.aliyuncs.com/api-ws/v1/realtime",
        api_key=api_key,
        model="qwen-omni-turbo-realtime-2025-05-08",
        voice="Chelsie",
        on_text_delta=on_text_output,
        on_audio_delta=handle_audio_data,
        on_input_transcript=on_input_done,
        on_output_transcript=lambda text: print(f"\n[è½¬å½•] {text}") if text else None,
        extra_event_handlers=extra_handlers,
        turn_detection_mode=TurnDetectionMode.SERVER_VAD  # ä½¿ç”¨æœåŠ¡å™¨VADè‡ªåŠ¨æ£€æµ‹
    )
    
    try:
        # è¿æ¥åˆ°æœåŠ¡å™¨
        print("æ­£åœ¨è¿æ¥åˆ°Qwenå®æ—¶æœåŠ¡...")
        await realtime_client.connect()
        print("âœ… è¿æ¥æˆåŠŸï¼")
        
        # é…ç½®VADå‚æ•°
        vad_config = {
            "event_id": "event_" + str(int(time.time() * 1000)),
            "type": "session.update",
            "session": {
                "turn_detection": {
                    "type": "server_vad",
                    "threshold": 0.5,  # VADé˜ˆå€¼
                    "prefix_padding_ms": 300,  # å‰ç¼€å¡«å……
                    "silence_duration_ms": 700  # é™éŸ³æŒç»­æ—¶é—´ï¼Œæ›´çŸ­çš„é™éŸ³æ£€æµ‹
                }
            }
        }
        await realtime_client.send_event(vad_config)
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = [
            asyncio.create_task(realtime_client.handle_messages()),
            asyncio.create_task(microphone_streaming(realtime_client)),
            asyncio.create_task(handle_recording_trigger(realtime_client))
        ]
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆç›´åˆ°ç”¨æˆ·ä¸­æ–­ï¼‰
        await asyncio.gather(*tasks)
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æ­£åœ¨é€€å‡ºç¨‹åº...")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
    finally:
        # åœæ­¢é”®ç›˜ç›‘å¬
        listener.stop()
        # æ¸…ç†èµ„æº
        audio_queue.put(None)  # å‘é€ç»“æŸä¿¡å·ç»™éŸ³é¢‘æ’­æ”¾çº¿ç¨‹
        if audio_player:
            audio_player.join(timeout=1)
        await realtime_client.close()
        p.terminate()
        print("âœ… ç¨‹åºå·²é€€å‡º")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²é€€å‡º")